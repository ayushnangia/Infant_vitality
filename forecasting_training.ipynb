{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMPORTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "# from statsmodels.tsa.arima_model import ARIMA\n",
    "# from statsmodels.tsa.arima_model import ARIMAResults\n",
    "import statsmodels.api as sm\n",
    "from darts import TimeSeries\n",
    "from darts.metrics.metrics import mae as meanabs ,mse,mape, r2_score\n",
    "from darts.models import NBEATSModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sktime.forecasting.compose import make_reduction, TransformedTargetForecaster\n",
    "from sktime.forecasting.model_selection import ExpandingWindowSplitter, ForecastingGridSearchCV\n",
    "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.linear_model import Lasso,LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error, mean_squared_log_error\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "tf.random.set_seed(7)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg = []\n",
    "# for i in range(10,13):\n",
    "#     for j in range(1,20):\n",
    "#         if i<10:\n",
    "#             path = \"../dataset/ECGData/Person_0{0}/rec_{1}\".format(i,j)\n",
    "#         else: \n",
    "#             path = \"../dataset/ECGData/Person_{0}/rec_{1}\".format(i,j)\n",
    "#         try:    \n",
    "#             record = wfdb.rdsamp(path)\n",
    "#             # data = np.array(record[0])\n",
    "#             data = record[0]\n",
    "#             data = data[:,1]\n",
    "            \n",
    "#             ecg.append(data)\n",
    "#             c+=1\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "for j in range(100,235):\n",
    "# for j in range(100,105):\n",
    "    path = \"../dataset/MIT-BIH/{}\".format(j)\n",
    "    try:    \n",
    "        record = wfdb.rdsamp(path)\n",
    "        # data = np.array(record[0])\n",
    "        data = record[0]\n",
    "        data = data[:,1]\n",
    "        # scaler = StandardScaler()\n",
    "        # ecg.append(scaler.fit_transform(data.reshape(-1,1)))\n",
    "        ecg.append(data)\n",
    "    \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# for j in range(10,12):\n",
    "#     if j<10:\n",
    "#         path = \"../dataset/FetalECG/ARR_0{}\".format(j)\n",
    "#     else:\n",
    "#         path = \"../dataset/FetalECG/ARR_{}\".format(j)\n",
    "#     try:    \n",
    "#         record = wfdb.rdsamp(path)\n",
    "#         # data = np.array(record[0])\n",
    "#         data = record[0]\n",
    "#         data = data[:,0]\n",
    "        \n",
    "#         ecg.append(data)\n",
    "        \n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "# for j in range(12,14):\n",
    "#     if j<10:\n",
    "#         path = \"../dataset/FetalECG/NR_0{}\".format(j)\n",
    "#     else:\n",
    "#         path = \"../dataset/FetalECG/NR_{}\".format(j)\n",
    "#     try:    \n",
    "#         record = wfdb.rdsamp(path)\n",
    "#         # data = np.array(record[0])\n",
    "#         data = record[0]\n",
    "#         data = data[:,0]\n",
    "        \n",
    "#         ecg.append(data)\n",
    "       \n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "# for j in range(1,2):\n",
    "#     path = \"../dataset/PretermECG/infant{}_ecg\".format(j)\n",
    "#     try:    \n",
    "#         record = wfdb.rdsamp(path)\n",
    "#         # data = np.array(record[0])\n",
    "#         data = record[0]\n",
    "#         data = data[:,0]\n",
    "        \n",
    "#         ecg.append(data)\n",
    "        \n",
    "        \n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "ecg = np.array(ecg)\n",
    "Data_ =[]\n",
    "for i in range(len(ecg)):\n",
    "    temp = [[t,ecg[i][t]] for t in range(len(ecg[i]))]\n",
    "    Data_.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=50):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.24863613180828933\n",
      "rmse:  0.18484619731012394\n",
      "r2:  -0.5303065015740012\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "\n",
    "for i in Data_:\n",
    "    i= np.array(i)\n",
    "    X = i[:,1]\n",
    "    # scaler = StandardScaler()\n",
    "    X = X.reshape(-1,1)\n",
    "    split_len = int(0.8*len(X))\n",
    "    X_train,y_test = X[:split_len] , X[split_len:]\n",
    "    model = sm.tsa.arima.ARIMA(X_train, order=(4,1,0))\n",
    "    model_fit = model.fit()\n",
    "    pred = model_fit.forecast(len(y_test))\n",
    "    # rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "# print( 'rmsle: ',np.mean(rmsle))\n",
    "# model = sm.tsa.arima.ARIMA(ecg[29][:-2000], order=(4,1,0))\n",
    "# model_fit = model.fit()\n",
    "# plt.plot(ecg[29][-2000:],'r')\n",
    "# # model_fit.predict()\n",
    "# plt.plot(model_fit.forecast(2000),'g')\n",
    "# plt.show()\n",
    "# print(sum(abs(ecg[29][-2000:]-model_fit.forecast(2000)))**2/len(ecg[23]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.8285750099788967\n",
      "rmse:  1.543666916550448\n",
      "r2:  -0.5303065029224769\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "\n",
    "for i in Data_:\n",
    "    i= np.array(i)\n",
    "    X = i[:,1]\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.reshape(-1,1))\n",
    "    split_len = int(0.8*len(X))\n",
    "    X_train,y_test = X[:split_len] , X[split_len:]\n",
    "    model = sm.tsa.arima.ARIMA(X_train, order=(4,1,0))\n",
    "    model_fit = model.fit()\n",
    "    pred = model_fit.forecast(len(y_test))\n",
    "    # rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "# print( 'rmsle: ',np.mean(rmsle))\n",
    "# model = sm.tsa.arima.ARIMA(ecg[29][:-2000], order=(4,1,0))\n",
    "# model_fit = model.fit()\n",
    "# plt.plot(ecg[29][-2000:],'r')\n",
    "# # model_fit.predict()\n",
    "# plt.plot(model_fit.forecast(2000),'g')\n",
    "# plt.show()\n",
    "# print(sum(abs(ecg[29][-2000:]-model_fit.forecast(2000)))**2/len(ecg[23]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.016333867884851628\n",
      "rmse:  0.008103178821084968\n",
      "r2:  0.9643295970811812\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i = np.array(i)\n",
    "    lasso = lgb.LGBMRegressor()\n",
    "    # scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = i.reshape(-1,1)\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    #rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    # plt.plot(pred[0:1000],'r')\n",
    "    # plt.plot(y_test[0:1000],'g')\n",
    "    # break\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "#print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.05984980579300179\n",
      "rmse:  0.042214161001337125\n",
      "r2:  0.9654806408729478\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i = np.array(i)\n",
    "    lasso = lgb.LGBMRegressor()\n",
    "    scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = scaler.transform(i.reshape(-1,1))\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    #rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    # plt.plot(pred[0:1000],'r')\n",
    "    # plt.plot(y_test[0:1000],'g')\n",
    "    # break\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "#print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.04307645944260089\n",
      "rmse:  0.006701546596643289\n",
      "r2:  0.79364205945286\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i= np.array(i)\n",
    "    lasso = Lasso(0.01)\n",
    "    # scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = i.reshape(-1,1)\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    #rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "#print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.07307049605210002\n",
      "rmse:  0.015806188154845528\n",
      "r2:  0.9840135783599019\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i= np.array(i)\n",
    "    lasso = Lasso(0.01)\n",
    "    scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = scaler.transform(i.reshape(-1,1))\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    #rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "#print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.01302615240967746\n",
      "rmse:  0.00036370334429897464\n",
      "r2:  0.9922780153127139\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i = np.array(i)\n",
    "    lasso = LinearRegression()\n",
    "    # scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = i.reshape(-1,1)\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    #rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "#print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.05627654837485021\n",
      "rmse:  0.0073897016321069235\n",
      "r2:  0.9922780153127135\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i = np.array(i)\n",
    "    lasso = LinearRegression()\n",
    "    scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = scaler.transform(i.reshape(-1,1))\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    #rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "#print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.065 -0.065 -0.065 ... -0.365 -0.335  0.   ]\n",
      "[-0.16 -0.16 -0.16 ... -0.11 -0.11  0.  ]\n",
      "[0.005 0.005 0.005 ... 0.2   0.195 0.   ]\n",
      "[0.05  0.05  0.05  ... 0.05  0.055 0.   ]\n",
      "[0.2   0.2   0.2   ... 0.2   0.205 0.   ]\n",
      "[ 0.26  0.26  0.26 ... -0.37 -0.38  0.  ]\n",
      "[0.195 0.195 0.195 ... 0.265 0.405 0.   ]\n",
      "[-1.245 -1.245 -1.245 ...  0.07   0.065  0.   ]\n",
      "[-0.78  -0.78  -0.78  ...  0.085  0.08   0.   ]\n",
      "[0.635 0.635 0.635 ... 0.36  0.365 0.   ]\n",
      "[ 0.035  0.035  0.035 ... -0.79  -0.795 -1.28 ]\n",
      "[-0.62 -0.62 -0.62 ... -0.59 -0.58  0.  ]\n",
      "[0.13 0.13 0.13 ... 0.03 0.03 0.  ]\n",
      "[ 0.015  0.015  0.015 ... -0.215 -0.225  0.   ]\n",
      "[-0.335 -0.335 -0.335 ...  0.24   0.24   0.   ]\n",
      "[-1.24  -1.24  -1.24  ... -0.715 -0.715 -1.28 ]\n",
      "[-0.47  -0.47  -0.47  ... -0.225 -0.245  0.   ]\n",
      "[-0.515 -0.515 -0.515 ... -2.1   -2.14  -2.56 ]\n",
      "[-0.47  -0.47  -0.47  ... -1.825 -1.74  -1.28 ]\n",
      "[-0.65  -0.65  -0.65  ... -0.695 -0.665 -1.28 ]\n",
      "[-0.735 -0.735 -0.735 ... -0.58  -0.585  0.   ]\n",
      "[-0.455 -0.455 -0.455 ... -0.705 -0.69  -1.28 ]\n",
      "[-0.685 -0.685 -0.685 ... -0.585 -0.57   0.   ]\n",
      "[ 0.105  0.105  0.105 ... -0.27  -0.27   0.   ]\n",
      "[-0.21  -0.21  -0.21  ... -0.055 -0.065  0.   ]\n",
      "[0.125 0.125 0.125 ... 0.1   0.11  0.   ]\n",
      "[0.065 0.065 0.065 ... 0.33  0.325 0.   ]\n",
      "[-0.54  -0.54  -0.54  ... -0.365 -0.38   0.   ]\n",
      "[ 0.095  0.095  0.095 ... -0.465 -0.4    0.   ]\n",
      "[ 0.19  0.19  0.19 ... -0.1  -0.11  0.  ]\n",
      "[ 0.16  0.16  0.16 ... -0.04 -0.04  0.  ]\n",
      "[0.135 0.135 0.135 ... 0.075 0.1   0.   ]\n",
      "[0.05  0.05  0.05  ... 0.235 0.22  0.   ]\n",
      "[-0.615 -0.615 -0.615 ... -1.49  -1.345 -1.28 ]\n",
      "[0.025 0.025 0.025 ... 0.265 0.245 0.   ]\n",
      "[0.185 0.185 0.185 ... 0.17  0.135 0.   ]\n",
      "[-0.76 -0.76 -0.76 ...  0.14  0.16  0.  ]\n",
      "[-0.955 -0.955 -0.955 ... -0.555 -0.55   0.   ]\n",
      "[-0.38 -0.38 -0.38 ... -0.17 -0.18  0.  ]\n",
      "[0.05  0.05  0.05  ... 0.08  0.075 0.   ]\n",
      "[-0.375 -0.375 -0.375 ...  0.17   0.18   0.   ]\n",
      "[-0.16  -0.16  -0.16  ... -0.335 -0.32   0.   ]\n",
      "[-0.095 -0.095 -0.095 ... -0.11  -0.115  0.   ]\n",
      "[-0.285 -0.285 -0.285 ... -0.16  -0.145  0.   ]\n",
      "[ 0.075  0.075  0.075 ... -0.195 -0.19   0.   ]\n",
      "[0.21  0.21  0.21  ... 0.015 0.035 0.   ]\n",
      "[0.01 0.01 0.01 ... 0.32 0.34 0.  ]\n",
      "[0.135 0.135 0.135 ... 0.075 0.08  0.   ]\n",
      "mae:  0.015402814296505224\n",
      "rmse:  0.007646812895037921\n",
      "r2:  0.9691221768410453\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i = np.array(i)\n",
    "    lasso = xgboost.XGBRegressor()\n",
    "    # scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = i.reshape(-1,1)\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    # rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    print(i)\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "# print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.05699804225654694\n",
      "rmse:  0.03831002817367366\n",
      "r2:  0.9690764025657513\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i = np.array(i)\n",
    "    lasso = xgboost.XGBRegressor()\n",
    "    scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = scaler.transform(i.reshape(-1,1))\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    # rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "# print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.015526374432526418\n",
      "rmse:  0.037534631709022534\n",
      "r2:  0.969301940338334\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i = np.array(i)\n",
    "    lasso = BaggingRegressor()\n",
    "    # scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = i.reshape(-1,1)\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    # rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "# print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  0.058200658611450164\n",
      "rmse:  0.12447187352322335\n",
      "r2:  0.969389934572724\n"
     ]
    }
   ],
   "source": [
    "rmsle =[]\n",
    "rmse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "for i in ecg:\n",
    "    i = np.array(i)\n",
    "    lasso = BaggingRegressor()\n",
    "    scaler = StandardScaler().fit(i.reshape(-1,1))\n",
    "    temp_data = scaler.transform(i.reshape(-1,1))\n",
    "    # X = i[:,0]\n",
    "    # Y = i[:,1] \n",
    "    train_size = int(len(temp_data) * 0.3)\n",
    "    test_size = len(temp_data) - train_size\n",
    "    train, test = temp_data[0:train_size,:], temp_data[train_size:len(temp_data),:]\n",
    "\n",
    "    ### train aur test column honge shayad\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    X_test, y_test = create_dataset(test)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2,  shuffle=False)\n",
    "\n",
    "    lasso = lasso.fit(X_train,y_train)\n",
    "    pred = lasso.predict(X_test)\n",
    "    # rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test,pred)))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    \n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('rmse: ',np.mean(rmse))\n",
    "print('r2: ',np.mean(r2))\n",
    "# print('rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N Beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | stacks        | ModuleList       | 1.2 M \n",
      "---------------------------------------------------\n",
      "1.2 M     Trainable params\n",
      "1.6 K     Non-trainable params\n",
      "1.2 M     Total params\n",
      "4.807     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 49398/49398 [33:42<00:00, 24.43it/s, train_loss=1.63e+3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 49398/49398 [33:42<00:00, 24.43it/s, train_loss=1.63e+3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Data =[]\n",
    "for i in range(len(ecg)):\n",
    "    scaler = StandardScaler().fit_transform(ecg[i].reshape(-1,1))\n",
    "    temp = [[t,scaler[t]] for t in range(len(ecg[i]))]\n",
    "    temp = TimeSeries.from_values(np.array(temp))\n",
    "    print(i)\n",
    "    Data.append(temp)\n",
    "np.random.shuffle(Data)\n",
    "train = Data[:int(len(Data)*0.8)]\n",
    "test =  Data[int(len(Data)*0.8):]\n",
    "    \n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "Nbeats = NBEATSModel(\n",
    "    input_chunk_length=30,\n",
    "    output_chunk_length=7,\n",
    "    generic_architecture=True,\n",
    "    num_stacks=8,\n",
    "    num_blocks=1,\n",
    "    num_layers=3,\n",
    "    layer_widths=256,\n",
    "    n_epochs=10,\n",
    "    nr_epochs_val_period=1,\n",
    "    batch_size=500,\n",
    "    model_name=\"nbeats\",\n",
    "    pl_trainer_kwargs ={\"accelerator\": \"gpu\", \"devices\": -1}\n",
    ")\n",
    "\n",
    "Nbeats = Nbeats.fit(train)\n",
    "\n",
    "Nbeats.save('../models/Nbeats_normalized.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [01:15<00:00, 75.61s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "Nbeats = NBEATSModel.load('../models/Nbeats_normalized.pt')\n",
    "rmse_ = []\n",
    "mae_ = []\n",
    "r2_ = []\n",
    "i = int((1/2)*len(Data[1]))\n",
    "\n",
    "for i in test:\n",
    "    n = int(len(i)*0.2)\n",
    "    tot = len(i)-n\n",
    "    pred = Nbeats.predict(n,i[:tot])\n",
    "    y = i[tot:]\n",
    "    rmse_.append(np.sqrt(mse(y,pred)))\n",
    "    mae_.append(meanabs(y,pred))\n",
    "    r2_.append(r2_score(y,pred))\n",
    "# print(sum((y-pred)**2)/len(y))\n",
    "\n",
    "print('rmse: ',np.mean(rmse_))\n",
    "print('mae: ',np.mean(mae_))\n",
    "print('mae: ',np.mean(r2_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Data =[]\n",
    "for i in range(len(ecg)):\n",
    "    scaler = ecg[i].reshape(-1,1)\n",
    "    temp = [[t,scaler[t]] for t in range(len(ecg[i]))]\n",
    "    temp = TimeSeries.from_values(np.array(temp))\n",
    "    print(i)\n",
    "    Data.append(temp)\n",
    "np.random.shuffle(Data)\n",
    "train = Data[:int(len(Data)*0.8)]\n",
    "test =  Data[int(len(Data)*0.8):]\n",
    "    \n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "Nbeats = NBEATSModel(\n",
    "    input_chunk_length=30,\n",
    "    output_chunk_length=7,\n",
    "    generic_architecture=True,\n",
    "    num_stacks=8,\n",
    "    num_blocks=1,\n",
    "    num_layers=3,\n",
    "    layer_widths=256,\n",
    "    n_epochs=10,\n",
    "    nr_epochs_val_period=1,\n",
    "    batch_size=500,\n",
    "    model_name=\"nbeats\",\n",
    "    pl_trainer_kwargs ={\"accelerator\": \"gpu\", \"devices\": -1}\n",
    ")\n",
    "\n",
    "Nbeats = Nbeats.fit(train)\n",
    "\n",
    "Nbeats.save('../models/Nbeats_.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')\n",
    "Nbeats = NBEATSModel.load('../models/Nbeats.pt')\n",
    "rmse_ = []\n",
    "mae_ = []\n",
    "r2_ = []\n",
    "i = int((1/2)*len(Data[1]))\n",
    "\n",
    "for i in test:\n",
    "    n = int(len(i)*0.2)\n",
    "    tot = len(i)-n\n",
    "    pred = Nbeats.predict(n,i[:tot])\n",
    "    y = i[tot:]\n",
    "    rmse_.append(np.sqrt(mse(y,pred)))\n",
    "    mae_.append(meanabs(y,pred))\n",
    "    r2_.append(r2_score(y,pred))\n",
    "# print(sum((y-pred)**2)/len(y))\n",
    "\n",
    "print('rmse: ',np.mean(rmse_))\n",
    "print('mae: ',np.mean(mae_))\n",
    "print('mae: ',np.mean(r2_))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMAX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rmsle =[]\n",
    "mse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "\n",
    "for i in Data_:\n",
    "    i= np.array(i)\n",
    "    X = i[:,1]\n",
    "    # scaler = StandardScaler()\n",
    "    X = X.reshape(-1,1)\n",
    "    split_len = int(0.8*len(X))\n",
    "    X_train,y_test = X[:split_len] , X[split_len:]\n",
    "    model = sm.tsa.statespace.SARIMAX(X_train, order=(7,1,7))\n",
    "    \n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    pred = model_fit.forecast(len(y_test))\n",
    "   \n",
    "    #rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    mse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    \n",
    "\n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('mse: ',np.mean(mse))\n",
    "print('r2: ',np.mean(r2))\n",
    "#print( 'rmsle: ',np.mean(rmsle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rmsle =[]\n",
    "mse =[]\n",
    "r2 =[]\n",
    "mae = []\n",
    "\n",
    "for i in Data_:\n",
    "    i= np.array(i)\n",
    "    X = i[:,1]\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X.reshape(-1,1))\n",
    "    split_len = int(0.8*len(X))\n",
    "    X_train,y_test = X[:split_len] , X[split_len:]\n",
    "    model = sm.tsa.statespace.SARIMAX(X_train, order=(7,1,7))\n",
    "    \n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    pred = model_fit.forecast(len(y_test))\n",
    "   \n",
    "    #rmsle.append(mean_squared_log_error(y_test,pred))\n",
    "    mse.append(mean_squared_error(y_test,pred))\n",
    "    r2.append(r2_score(y_test,pred))\n",
    "    mae.append(mean_absolute_error(y_test,pred))\n",
    "    \n",
    "\n",
    "print(\"mae: \",np.mean(mae))\n",
    "print('mse: ',np.mean(mse))\n",
    "print('r2: ',np.mean(r2))\n",
    "#print( 'rmsle: ',np.mean(rmsle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
